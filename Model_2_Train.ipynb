{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Robin\\AppData\\Local\\Temp\\ipykernel_37128\\24878954.py:11: DeprecationWarning: support for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python 3.14\n",
      "  DIR_DATASET = Path(current_dir=os.getcwd()).parent.absolute()/'dataset_DocRED'\n",
      "C:\\Users\\Robin\\AppData\\Local\\Temp\\ipykernel_37128\\24878954.py:15: DeprecationWarning: support for supplying keyword arguments to pathlib.PurePath is deprecated and scheduled for removal in Python 3.14\n",
      "  DIR_DATASET_PREP = Path(current_dir=os.getcwd()).parent.absolute()/'dataset_prep'\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths preprocessed datasets, generated by utils/prep.py (to speed up training)\n",
    "DIR_DATASET = Path(current_dir=os.getcwd()).parent.absolute()/'dataset_DocRED'\n",
    "DATA_DEV = DIR_DATASET/'dev.json' \n",
    "DATA_TRAIN = DIR_DATASET/'train_annotated.json'\n",
    "\n",
    "DIR_DATASET_PREP = Path(current_dir=os.getcwd()).parent.absolute()/'dataset_prep'\n",
    "DATA_DEV_PREP = DIR_DATASET_PREP/'dev_prep.pickle' \n",
    "DATA_TRAIN_PREP = DIR_DATASET_PREP/'train_annotated_prep.pickle'\n",
    "\n",
    "PATH_UTILS = DIR_DATASET.parent.absolute().__str__()\n",
    "\n",
    "# add local lib to path\n",
    "if PATH_UTILS not in sys.path:\n",
    "    sys.path.append(PATH_UTILS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DocREDDataset, collate_fn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "# load preped dataset\n",
    "fData = open(DATA_TRAIN_PREP.__str__(), 'rb')\n",
    "data = pickle.load(fData)\n",
    "fData.close()\n",
    "\n",
    "# train/val split\n",
    "train_size = int(0.8 * len(data))  # 80% for training\n",
    "val_size = len(data) - train_size  # 20% for validation\n",
    "\n",
    "# test dataset\n",
    "fData = open(DATA_DEV_PREP.__str__(), 'rb')\n",
    "data_test = pickle.load(fData)\n",
    "fData.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "from torch import nn\n",
    "from pytorch_tcn import TemporalConv1d\n",
    "\n",
    "# TCN block\n",
    "class TCN_Block(nn.Module):\n",
    "    def __init__(self, in_features, out_features, kernel_size=7, stride=1, dilation=1, dropout=0.3):\n",
    "        super(TCN_Block, self).__init__()\n",
    "\n",
    "        # temporal conv with weight_norm\n",
    "        self.res = nn.Conv1d(in_features, out_features, kernel_size=1) # 1x1 conv sampling for residual\n",
    "        self.conv = nn.utils.parametrizations.weight_norm(TemporalConv1d(in_features, out_features, kernel_size, stride, dilation=dilation))\n",
    "        self.relu = nn.ReLU() \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) # Dilated Causal Conv\n",
    "        x = self.dropout(self.relu(x)) # dropout regularization\n",
    "        return x\n",
    "\n",
    "# The model\n",
    "class LSTM_TCNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, hidden_dims_tcn, dropout=0.3):\n",
    "        super(LSTM_TCNClassifier, self).__init__()\n",
    "        self.coref_embed = nn.Embedding(512, 20, padding_idx=0)\n",
    "        self.ner_embed = nn.Embedding(512, 20, padding_idx=0)\n",
    "\n",
    "        # tcn\n",
    "        tcn_layers = []\n",
    "        for i in range(len(hidden_dims_tcn)):\n",
    "            in_features = 0\n",
    "            if i == 0:\n",
    "                in_features = input_dim\n",
    "            else:\n",
    "                in_features = hidden_dims_tcn[i-1]\n",
    "            out_features = hidden_dims_tcn[i]\n",
    "            dilation = 2 ** i # dilation 1, 2, 4, ...\n",
    "            tcn_layer = TCN_Block(in_features, out_features, dilation=dilation, dropout=dropout)\n",
    "            tcn_layers.append(tcn_layer)\n",
    "        self.tcn = nn.Sequential(*tcn_layers)\n",
    "\n",
    "        # lstm\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # layer norms\n",
    "        self.ln_h = nn.LayerNorm(hidden_dim)\n",
    "        self.ln_t = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # classification\n",
    "        self.dropout1 = nn.Dropout(p=dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim+hidden_dims_tcn[-1], hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # bilinear output\n",
    "        self.bln = nn.Bilinear(hidden_dim*2, hidden_dim*2, output_dim)\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=-1) # NOTE: removed, output bilinear, use sigmoid later\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def forward(self, embed, coref, ner, map_h, map_t):\n",
    "        # coref \n",
    "        coref = self.coref_embed(coref)\n",
    "        # ner (coref_type)\n",
    "        ner = self.ner_embed(ner)\n",
    "        \n",
    "        net_in = torch.cat([embed, coref, ner], dim=-1)\n",
    "\n",
    "        # tcn\n",
    "        tcn_out = self.tcn(net_in.transpose(-1, -2)).transpose(-1, -2)\n",
    "\n",
    "        # lstm\n",
    "        hidden, carry = torch.zeros(self.num_layers, net_in.shape[0], self.hidden_dim).to(embed.device), torch.zeros(self.num_layers, net_in.shape[0], self.hidden_dim).to(embed.device)\n",
    "        # xavier init hidden and carry for stability over randn\n",
    "        nn.init.xavier_normal_(hidden)\n",
    "        nn.init.xavier_normal_(carry)\n",
    "        lstm_out, (hidden, carry) = self.lstm(net_in, (hidden, carry))\n",
    "\n",
    "\n",
    "        # Extract features from time sequence output\n",
    "\n",
    "        # concat tcn and lstm features\n",
    "        seq_out = torch.cat([tcn_out, lstm_out], dim=-1)\n",
    "        # linear layer\n",
    "        seq_out = self.dropout1(self.relu1(self.fc1(seq_out)))\n",
    "\n",
    "        # saperate features for head and tail entities\n",
    "        map_h = map_h.float().unsqueeze(1)\n",
    "        map_t = map_t.float().unsqueeze(1)\n",
    "\n",
    "        seq_out_h = self.ln_h(torch.matmul(map_h, seq_out).squeeze(1)) \n",
    "        seq_out_t = self.ln_t(torch.matmul(map_t, seq_out).squeeze(1))\n",
    "\n",
    "        dist = seq_out_t - seq_out_h\n",
    "\n",
    "        seq_out_h = torch.concat([seq_out_h, dist], dim=-1)\n",
    "        seq_out_t = torch.concat([seq_out_t, -dist], dim=-1)\n",
    "        \n",
    "        # bilinear output\n",
    "        out = self.bln(seq_out_h, seq_out_t)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Setup & Training\n",
    "\n",
    "(Note: Training took about 1 hour on a machine with 8C16T CPU and Nvidia RTX 3060-12G, loading the pre-processed training and testing datasets takes around 26GB of RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3053/3053 [00:04<00:00, 664.49it/s]\n",
      "epoch 1 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.48it/s]\n",
      "epoch 1 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.09923500584679677, loss_val=0.04370540759847157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2 [Train]: 100%|██████████| 1413/1413 [01:19<00:00, 17.73it/s]\n",
      "epoch 2 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.0380226759304624, loss_val=0.03458818678591548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.57it/s]\n",
      "epoch 3 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.03230339437011321, loss_val=0.030130370114903667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.63it/s]\n",
      "epoch 4 [Val]: 100%|██████████| 354/354 [00:06<00:00, 53.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.02823377774483923, loss_val=0.027013055185687408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 18.08it/s]\n",
      "epoch 5 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.02579704144744167, loss_val=0.025349992330022955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 6 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 17.94it/s]\n",
      "epoch 6 [Val]: 100%|██████████| 354/354 [00:05<00:00, 59.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.02396405703254355, loss_val=0.023826376945411756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 7 [Train]: 100%|██████████| 1413/1413 [01:14<00:00, 18.94it/s]\n",
      "epoch 7 [Val]: 100%|██████████| 354/354 [00:05<00:00, 59.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.02289556536654779, loss_val=0.023391788336053744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.55it/s]\n",
      "epoch 8 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.021651953403420764, loss_val=0.021935891812551494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 18.05it/s]\n",
      "epoch 9 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.020722564876011013, loss_val=0.021230052880374557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 17.90it/s]\n",
      "epoch 10 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01978014661981253, loss_val=0.02088314535801357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11 [Train]: 100%|██████████| 1413/1413 [01:19<00:00, 17.81it/s]\n",
      "epoch 11 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01909405220516147, loss_val=0.020507659173786302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12 [Train]: 100%|██████████| 1413/1413 [01:21<00:00, 17.42it/s]\n",
      "epoch 12 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.018426775104469724, loss_val=0.019676966134900765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 17.98it/s]\n",
      "epoch 13 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.017721330050988054, loss_val=0.019180246165790463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.51it/s]\n",
      "epoch 14 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01702737514165567, loss_val=0.018649179877786987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 15 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.28it/s]\n",
      "epoch 15 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.016569984415038545, loss_val=0.01942865483957411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 16 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.42it/s]\n",
      "epoch 16 [Val]: 100%|██████████| 354/354 [00:06<00:00, 57.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.015976311923027755, loss_val=0.01820666954252806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 17 [Train]: 100%|██████████| 1413/1413 [01:22<00:00, 17.08it/s]\n",
      "epoch 17 [Val]: 100%|██████████| 354/354 [00:11<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01561735679612344, loss_val=0.01802023553610437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 18 [Train]: 100%|██████████| 1413/1413 [02:21<00:00,  9.97it/s]\n",
      "epoch 18 [Val]: 100%|██████████| 354/354 [00:11<00:00, 30.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.015089344437928146, loss_val=0.018036268360775997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 19 [Train]: 100%|██████████| 1413/1413 [01:48<00:00, 13.06it/s]\n",
      "epoch 19 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.014536666109767773, loss_val=0.017535545947398506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 20 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 17.99it/s]\n",
      "epoch 20 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.014234608591264622, loss_val=0.017758073140525042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 21 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.51it/s]\n",
      "epoch 21 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.013807720323116304, loss_val=0.017693323501527816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 22 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.26it/s]\n",
      "epoch 22 [Val]: 100%|██████████| 354/354 [00:06<00:00, 57.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.013394339832029735, loss_val=0.017294220853923153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 23 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.27it/s]\n",
      "epoch 23 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.013135707212818993, loss_val=0.01718871013292948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 24 [Train]: 100%|██████████| 1413/1413 [01:15<00:00, 18.67it/s]\n",
      "epoch 24 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.012841141669993188, loss_val=0.017068702029064298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 25 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.16it/s]\n",
      "epoch 25 [Val]: 100%|██████████| 354/354 [00:06<00:00, 53.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01243465213712782, loss_val=0.01731632756842774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 26 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.28it/s]\n",
      "epoch 26 [Val]: 100%|██████████| 354/354 [00:06<00:00, 57.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.012083404182712828, loss_val=0.01640091766208663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 27 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.23it/s]\n",
      "epoch 27 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.011909404738232102, loss_val=0.01721917396926947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 28 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.15it/s]\n",
      "epoch 28 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.011558195263983106, loss_val=0.017244525460294834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 29 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.35it/s]\n",
      "epoch 29 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.011261714377189392, loss_val=0.01698096383278821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 30 [Train]: 100%|██████████| 1413/1413 [01:16<00:00, 18.54it/s]\n",
      "epoch 30 [Val]: 100%|██████████| 354/354 [00:06<00:00, 57.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.011001049437127106, loss_val=0.01708690661379257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 31 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.20it/s]\n",
      "epoch 31 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.010808224304034114, loss_val=0.01694497534621107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 32 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.12it/s]\n",
      "epoch 32 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.01062103326205673, loss_val=0.017438207128174645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 33 [Train]: 100%|██████████| 1413/1413 [01:17<00:00, 18.34it/s]\n",
      "epoch 33 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.010284042888273526, loss_val=0.017149439691907943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 34 [Train]: 100%|██████████| 1413/1413 [01:15<00:00, 18.61it/s]\n",
      "epoch 34 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.010171272889470388, loss_val=0.01768958292859422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 35 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.61it/s]\n",
      "epoch 35 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009878353946542358, loss_val=0.01743033582655092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 36 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.50it/s]\n",
      "epoch 36 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009726862814962885, loss_val=0.017550370729617817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 37 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.54it/s]\n",
      "epoch 37 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009481017178080064, loss_val=0.017489361366267595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 38 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.54it/s]\n",
      "epoch 38 [Val]: 100%|██████████| 354/354 [00:06<00:00, 53.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009387914780777815, loss_val=0.017989697341286276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 39 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.59it/s]\n",
      "epoch 39 [Val]: 100%|██████████| 354/354 [00:06<00:00, 52.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009072749717299473, loss_val=0.01837551852788166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 40 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.52it/s]\n",
      "epoch 40 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.009077849147857153, loss_val=0.01779325572921142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 41 [Train]: 100%|██████████| 1413/1413 [01:19<00:00, 17.74it/s]\n",
      "epoch 41 [Val]: 100%|██████████| 354/354 [00:06<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.0087886632682778, loss_val=0.017915038672133773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 42 [Train]: 100%|██████████| 1413/1413 [01:19<00:00, 17.77it/s]\n",
      "epoch 42 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.00864788932883644, loss_val=0.018017050172833695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 43 [Train]: 100%|██████████| 1413/1413 [01:19<00:00, 17.69it/s]\n",
      "epoch 43 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.008538814034657019, loss_val=0.018524492743535566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 44 [Train]: 100%|██████████| 1413/1413 [01:21<00:00, 17.39it/s]\n",
      "epoch 44 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.008360336781103726, loss_val=0.018115746703177775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 45 [Train]: 100%|██████████| 1413/1413 [01:21<00:00, 17.24it/s]\n",
      "epoch 45 [Val]: 100%|██████████| 354/354 [00:06<00:00, 53.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.008216633321849203, loss_val=0.0186206615374734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 46 [Train]: 100%|██████████| 1413/1413 [01:21<00:00, 17.29it/s]\n",
      "epoch 46 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.00801075038525506, loss_val=0.01894528611621025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 47 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.60it/s]\n",
      "epoch 47 [Val]: 100%|██████████| 354/354 [00:06<00:00, 58.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.007922463105765408, loss_val=0.018242453193386732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 48 [Train]: 100%|██████████| 1413/1413 [01:18<00:00, 17.99it/s]\n",
      "epoch 48 [Val]: 100%|██████████| 354/354 [00:06<00:00, 56.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.007874741356326195, loss_val=0.01985068650821508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 49 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.63it/s]\n",
      "epoch 49 [Val]: 100%|██████████| 354/354 [00:06<00:00, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.007554659471957189, loss_val=0.019216489612445823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 50 [Train]: 100%|██████████| 1413/1413 [01:20<00:00, 17.58it/s]\n",
      "epoch 50 [Val]: 100%|██████████| 354/354 [00:06<00:00, 54.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train=0.007452232037573362, loss_val=0.018806043190166016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_dim = 768 + 20 + 20  # DistilledBERT pretrained embeddings + coref + ner type (both head and tail)\n",
    "hidden_dim = 128\n",
    "hidden_dims_tcn=[256,128,64]\n",
    "dropout = 0.5\n",
    "output_dim = 96 + 1  # 96 types + Na\n",
    "num_layers = 2\n",
    "batch_size = 32\n",
    "learning_rate = 0.0002\n",
    "max_epochs = 50 # has to be multiple of k_folds\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "# Split dataset for training and validation\n",
    "dataset = DocREDDataset(data, na_factor=0.5) # introduce new random NA examples in new k-fold cycle\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "# model\n",
    "model = LSTM_TCNClassifier(input_dim, hidden_dim, output_dim, num_layers, dropout=dropout, hidden_dims_tcn=hidden_dims_tcn).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss() # Classification loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(model, embed, coref, ner, y, map_h, map_t):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(embed, coref, ner, map_h, map_t)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "import numpy as np\n",
    "# store train losses\n",
    "losses_train = []\n",
    "losses_val = []\n",
    "\n",
    "# training loop\n",
    "(DIR_DATASET_PREP.parent/'checkpoints').mkdir(exist_ok=True) # create output directory\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    # train\n",
    "    train_loss = []\n",
    "    for batch in tqdm(train_loader, desc=f\"epoch {epoch} [Train]\"):\n",
    "        x, y = batch\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        embed = x[:,:,:768]\n",
    "        coref = x[:,:,768].long()\n",
    "        ner = x[:,:,769].long()\n",
    "        map_h = x[:,:,770]\n",
    "        map_t = x[:,:,771]\n",
    "\n",
    "        loss = train(model, embed, coref, ner, y, map_h, map_t)\n",
    "        train_loss.append(loss)\n",
    "    avg_train_loss = sum(train_loss)/len(train_loss)\n",
    "    losses_train.append(avg_train_loss)\n",
    "\n",
    "    # val\n",
    "    val_loss = []\n",
    "    for batch in tqdm(val_loader, desc=f\"epoch {epoch} [Val]\"):\n",
    "        with torch.no_grad():\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            embed = x[:,:,:768]\n",
    "            coref = x[:,:,768].long()\n",
    "            ner = x[:,:,769].long()\n",
    "            map_h = x[:,:,770]\n",
    "            map_t = x[:,:,771]\n",
    "            outputs = model(embed, coref, ner, map_h, map_t)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss.append(loss.item())\n",
    "    avg_val_loss = sum(val_loss)/len(val_loss)\n",
    "    losses_val.append(avg_val_loss)\n",
    "\n",
    "    print(f\"loss_train={avg_train_loss}, loss_val={avg_val_loss}\")\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        # save checkpoint \n",
    "        torch.save(model.state_dict(), DIR_DATASET_PREP.parent/'checkpoints'/f'lstm_tcn_{epoch}e.model')\n",
    "\n",
    "# save loss for logging\n",
    "loss_train = np.array(losses_train)\n",
    "np.save(DIR_DATASET_PREP.parent/'checkpoints'/'loss_train.npy', loss_train)\n",
    "loss_val = np.array(losses_val)\n",
    "np.save(DIR_DATASET_PREP.parent/'checkpoints'/'loss_val.npy', loss_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DocRED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
